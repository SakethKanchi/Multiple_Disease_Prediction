{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Description**\n",
        "The dataset contains several medical predictor (Independent) variables and one target variable, (Outcome). Predictor variables include:\n",
        "\n",
        "  1. age\n",
        "  2. sex\n",
        "  3. chest pain type (4 values)\n",
        "  4. resting blood pressure\n",
        "  5. serum cholestoral in mg/dl\n",
        "  6. fasting blood sugar > 120 mg/dl\n",
        "  7. resting electrocardiographic results (values 0,1,2)\n",
        "  8. maximum heart rate achieved\n",
        "  9. exercise induced angina\n",
        "  10. oldpeak = ST depression induced by exercise relative to rest\n",
        "  11. the slope of the peak exercise ST segment\n",
        "  12. number of major vessels (0-3) colored by flourosopy\n",
        "  13. thal: 0 = normal; 1 = fixed defect; 2 = reversable defect\n",
        "\n",
        "  Dataset url: https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m4QkSpZ9mbae"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTb-9TFFqprC"
      },
      "source": [
        "# **Step 1: Importing the Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q9U3S_whh3-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egMd5zeurTMR"
      },
      "source": [
        "# **Step 2: Load the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q-3-LkQrREV"
      },
      "source": [
        "# loading the csv data to a Pandas DataFrame\n",
        "heart_data = pd.read_csv('/content/heart.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Exploratory Data Analysis**\n",
        "Exploratory Data Analysis (EDA), also known as Data Exploration, is a step in the Data Analysis Process, where a number of techniques are used to better understand the dataset being used.\n",
        "\n",
        "**3.1) Understanding Your Variables** \n",
        "\n",
        "            3.1.1) Head of the dataset\n",
        "            3.1.2) The shape of the dataset\n",
        "            3.1.3) List types of columns\n",
        "            3.1.4) Info of the dataset\n",
        "            3.1.5) Summary of the dataset\n",
        "\n",
        "**3.1.1) Head of the Dataset**"
      ],
      "metadata": {
        "id": "CpWYvgIbnQGO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8dQxSTqriWD"
      },
      "source": [
        "# Display first five records\n",
        "heart_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx_aCZDgrqdR"
      },
      "source": [
        "# Display last five records\n",
        "heart_data.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1.2)The Shape of Dataset**"
      ],
      "metadata": {
        "id": "uzPX4t-Hnx63"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nX1tIzbrz0u"
      },
      "source": [
        "# number of rows and columns in the dataset\n",
        "heart_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1.3)List types of columns**"
      ],
      "metadata": {
        "id": "oZjLMCean8aL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart_data.dtypes"
      ],
      "metadata": {
        "id": "UYFagTPOoH5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1.4)Info of Dataset**"
      ],
      "metadata": {
        "id": "qBJvKol2oOnz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_xTcw1Sr6aJ"
      },
      "source": [
        "# getting some info about the data\n",
        "heart_data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjHtW31rsGlb"
      },
      "source": [
        "# checking for missing values\n",
        "heart_data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHmcP7DJsSEP"
      },
      "source": [
        "# Statistical Summary\n",
        "heart_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4InaOSIUsfWP"
      },
      "source": [
        "# checking the distribution of Target Variable\n",
        "heart_data['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSOBu4qDtJy5"
      },
      "source": [
        "1 --> Defective Heart\n",
        "\n",
        "0 --> Healthy Heart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW8i4igjtPRC"
      },
      "source": [
        "# **Step 4: Split the data frame in X & Y**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6yfbswrs7m3"
      },
      "source": [
        "X = heart_data.drop(columns='target', axis=1)\n",
        "Y = heart_data['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJoCp4ZKtpZy"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nukuj-YItq1w"
      },
      "source": [
        "Y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Applying Feature Scaling**\n",
        "Various Data Scaling Techniques:\n",
        "\n",
        "1.   Normalizer\n",
        "2.   MinMax Scaler\n",
        "3.   Binarizer\n",
        "4.   Standard Scaler"
      ],
      "metadata": {
        "id": "yKNhKjuZpBiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Standard Scaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "SSX = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "1Tpcp4kRpNuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EcjSE3Et18n"
      },
      "source": [
        "# **Step 6: Splitting the Data into Training data & Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-UUfRUxtuga"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7PrjC6zuf6X"
      },
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 7: Building Classification Algorithm**"
      ],
      "metadata": {
        "id": "AlqbaKeBpXgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**7.1) Logistic Regression**"
      ],
      "metadata": {
        "id": "Nf5RBvOeph4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(solver='liblinear',multi_class='ovr')\n",
        "lr.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "opa2DLu3pcg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**7.2) K-Nearest Neighbors Classifier(KNN)**"
      ],
      "metadata": {
        "id": "CjlLSrjPpioV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "XzLSNFk9pk2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**7.3) Naive-Bayes Classifier**"
      ],
      "metadata": {
        "id": "Y_IBY-FXpokh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "t618Te3upoTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**7.4) Support Vector Machine (SVM)**"
      ],
      "metadata": {
        "id": "1P-FMjDHptJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "sv = SVC(kernel='linear')\n",
        "sv.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "qX2IHraNpvUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**7.5) Decision Tree**"
      ],
      "metadata": {
        "id": "8iP3Zs7Qpw5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "N1ycWEc0p0UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**7.6) Random Forest**"
      ],
      "metadata": {
        "id": "WQobVdAfp18K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=20, random_state=12,max_depth=6)\n",
        "rf.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "RqMr6q-lp49V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 8: Making Prediction**"
      ],
      "metadata": {
        "id": "o8Cpt9r8qkmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**8.1) Making Prediction using Logistic Regression**"
      ],
      "metadata": {
        "id": "QHI1JxZaqtF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Initial shape: {X_test.shape}')\n",
        "lr_pred = lr.predict(X_test)\n",
        "print(f'{lr_pred.shape}')"
      ],
      "metadata": {
        "id": "lATNaxjjqp79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **8.2) Making Prediction using KNN**"
      ],
      "metadata": {
        "id": "ghhfro2zqx5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_pred = knn.predict(X_test) \n",
        "knn_pred.shape"
      ],
      "metadata": {
        "id": "jxiOCo38qyUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **8.3) Making Prediction using Naive Bayes**"
      ],
      "metadata": {
        "id": "Qyski3hLqyuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_pred = nb.predict(X_test)\n",
        "nb_pred.shape"
      ],
      "metadata": {
        "id": "7eBTATZeqzD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **8.4) Making Prediction using SVM**"
      ],
      "metadata": {
        "id": "CkXGju82qzR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sv_pred = sv.predict(X_test)\n",
        "sv_pred.shape"
      ],
      "metadata": {
        "id": "geD4RNJqqzrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **8.5) Making Prediction using Decision Tree**"
      ],
      "metadata": {
        "id": "CQrYsFWvq0CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_pred = dt.predict(X_test)"
      ],
      "metadata": {
        "id": "ETITKsjgq0Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **8.6) Making Prediciton using Random Forest**"
      ],
      "metadata": {
        "id": "pb4LuFP9rDYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_pred = rf.predict(X_test)"
      ],
      "metadata": {
        "id": "1s9f6piprD6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 9: Model Evaluation**"
      ],
      "metadata": {
        "id": "k_l71fqwrTMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "90SpaisJra6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train & Test Scores of Logistic Regression\n",
        "print(\"Accuracy (Train) score of Logistic Regression \",lr.score(X_train,Y_train)*100)\n",
        "print(\"Accuracy (Test) score of Logistic Regression \", lr.score(X_test,Y_test)*100)\n",
        "print(\"Accuracy score of Logistic Regression \", accuracy_score(Y_test,lr_pred)*100)"
      ],
      "metadata": {
        "id": "yK7WAFMqrbcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train & Test Scores of KNN\n",
        "print(\"Accuracy (Train) score of KNN \",knn.score(X_train,Y_train)*100)\n",
        "print(\"Accuracy (Test) score of KNN \", knn.score(X_test,Y_test)*100)\n",
        "print(\"Accuracy score of KNN \", accuracy_score(Y_test,knn_pred)*100)"
      ],
      "metadata": {
        "id": "_jTt5WWIrgoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train & Test Scores of Naive-Bayes\n",
        "print(\"Accuracy (Train) score of Naive Bayes \",nb.score(X_train,Y_train)*100)\n",
        "print(\"Accuracy (Test) score of Naive Bayes \", nb.score(X_test,Y_test)*100)\n",
        "print(\"Accuracy score of Naive Bayes \", accuracy_score(Y_test,nb_pred)*100)"
      ],
      "metadata": {
        "id": "tyqUrPnTrg2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train & Test Scores of SVM\n",
        "print(\"Accuracy (Train) score of SVM \",sv.score(X_train,Y_train)*100)\n",
        "print(\"Accuracy (Test) score of SVM \", sv.score(X_test,Y_test)*100)\n",
        "print(\"Accuracy score of SVM \", accuracy_score(Y_test,sv_pred)*100)"
      ],
      "metadata": {
        "id": "XAYL66_ArhBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train & Test Scores of Decision Tree\n",
        "print(\"Accuracy (Train) score of Decision Tree \",dt.score(X_train,Y_train)*100)\n",
        "print(\"Accuracy (Test) score of Decision Tree \", dt.score(X_test,Y_test)*100)\n",
        "print(\"Accuracy score of Decision Tree \", accuracy_score(Y_test,dt_pred)*100)"
      ],
      "metadata": {
        "id": "uJTPr497rhLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train & Test Scores of Random Forest\n",
        "print(\"Accuracy (Train) score of Random Forest \",rf.score(X_train,Y_train)*100)\n",
        "print(\"Accuracy (Test) score of Random Forest \", rf.score(X_test,Y_test)*100)\n",
        "print(\"Accuracy score of Random Forest \", accuracy_score(Y_test,rf_pred)*100)"
      ],
      "metadata": {
        "id": "BeoEbAXSrhVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIruVh3Qwq0e"
      },
      "source": [
        "# **Step 10: Building a Predictive System**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ercruC9wb4C"
      },
      "source": [
        "input_data = (63,1,3,145,233,1,0,150,0,2.3,0,0,1)\n",
        "\n",
        "# change the input data to a numpy array\n",
        "input_data_as_numpy_array= np.asarray(input_data)\n",
        "\n",
        "# reshape the numpy array as we are predicting for only on instance\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "prediction = dt.predict(input_data_reshaped)\n",
        "print(prediction)\n",
        "\n",
        "if (prediction[0]== 0):\n",
        "  print('The Person does not have a Heart Disease')\n",
        "else:\n",
        "  print('The Person has Heart Disease')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCHCMHpshHU4"
      },
      "source": [
        "# **Step 11 : Saving the trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdmTOR4MhHCB"
      },
      "source": [
        "import pickle\n",
        "import pickle\n",
        "filename = 'heart_disease_model.sav'\n",
        "pickle.dump(lr,open(filename,'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}